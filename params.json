{"name":"Wlst-2016","tagline":"Our presentation at Workshop on Large Scale Tomography titled Applying Big Data Solutions to Big Tomographic Problems ","body":"# Applying Big Data Solutions to Big Tomographic Problems\r\n\r\nThe presentation for the Workshop on Large-Scale Tomography in Szeged, Hungary in January 2016.\r\n- The [slides](https://rawgit.com/4Quant/WLST-2016/master/Slides.html) can be seen here\r\n- A Demo of our [Quantitative Image Search Engine](https://kmader.shinyapps.io/SearchMachineDemo)\r\n\r\n## Abstract\r\nWith every more efficient detectors, higher flux, and stable beamlines, comes the ability to probe \r\n\r\ntime and length-scales previously unachievable. Of particular interest are the massive scale \r\n\r\nprojects like the Human Brain Project, adult Zebra fish imaging, and dynamic imaging. All \r\n\r\ninvolve thousands to millions of measurements at the highest possible resolutions to cover mm \r\n\r\nto nanometer length scales. The task of processing and analyzing such large collections of \r\n\r\nmeasurements is exceptionally difficult. We show how the commodity hardware-based ‘Big \r\n\r\nData’ solutions can be adapted to the scientific domain to  address the processing terabytes \r\n\r\nworth of measurements in a parallel, distributed manner. Building on the distributed frameworks \r\n\r\nof Apache Spark and Spark Imaging Layer, we have extended the common tomographic and \r\n\r\nimage processing tools to work on these images enabling the use of many machines in parallel \r\n\r\nand drastically accelerating the speed and ease with which these large datasets can be stitched \r\n\r\nand analyzed. Our most recent developments enable the data to be analyzed and processed in \r\n\r\nreal-time using the latest streaming and micro-batch processing techniques. Unique such an \r\n\r\napproach allows for fault-tolerant, distributed analytics to process complicated datasets and \r\n\r\neventually provide feedback to both experimentalists and their equipment to allow for adaptation \r\n\r\nof measurements.\r\n\r\n## Relevant Links\r\n\r\n- [Quantitative Big Imaging Course](http://kmader.github.io/Quantitative-Big-Imaging-2015/)\r\n- [X-Ray Imaging Group at ETH Zurich](http://www.biomed.ee.ethz.ch/research/x-ray_imaging)\r\n- [Presentation at Spark Summit 2014](http://4quant.com/spark-summit-2014-presentation)\r\n- [Spark Introduction](http://4quant.com/spark-introduction/)\r\n\r\n## Bio\r\nKevin Mader is the founder and CTO of 4Quant and a lecturer in Image Analysis at ETH Zurich. He focuses on turning big hairy 3D images into simple, robust, reproducible numbers without resorting to black boxes or magic. In particular, as part of several collaborations, he is currently working on automatically segmenting full animal zebrafish images, characterizing rheology in 3D flows, and measuring viral infection dynamics in cell lines.\r\n\r\n\r\n","google":"UA-48764461-1","note":"Don't delete this file! It's used internally to help with page regeneration."}